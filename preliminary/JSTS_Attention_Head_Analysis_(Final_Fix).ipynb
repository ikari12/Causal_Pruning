{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Personal Computer Environment Setup"
      ],
      "metadata": {
        "id": "Rk5S1Tt-88Jb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OS Packages"
      ],
      "metadata": {
        "id": "EBapNpZt9LGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install mecab libmecab-dev mecab-ipadic-utf8 -y"
      ],
      "metadata": {
        "id": "AKaacLk-5KOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fugashi unidic-lite"
      ],
      "metadata": {
        "id": "2PXzwmSw5Sfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pyhon Packages (Session Break)"
      ],
      "metadata": {
        "id": "_b6TnFcN9S6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformer-lens einops"
      ],
      "metadata": {
        "id": "eCdgM9q45nH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python Old Version Packages"
      ],
      "metadata": {
        "id": "xqVX9Sgm9ct2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==3.6.0"
      ],
      "metadata": {
        "id": "eMPalhpBXXN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "A7AHWTdY9C7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The simplest CC pruning method"
      ],
      "metadata": {
        "id": "jDOwhHNa9xR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "This script serves as a proof-of-concept for Phase 1 of the proposed research.\n",
        "\n",
        "---\n",
        "FINAL VICTORY VERSION:\n",
        "- This definitive version ensures full reproducibility by setting all random seeds\n",
        "  and configuring PyTorch's CUDA backend for deterministic operations.\n",
        "---\n",
        "\"\"\"\n",
        "# ---------------------------------------------------------------------------\n",
        "#  *** PRE-EXECUTION SETUP (MANDATORY) ***\n",
        "# 1. Place the `requirements.txt` file (using `datasets==2.10.1`) in the same directory.\n",
        "# 2. In your terminal or Colab cell, run: `!pip install -r requirements.txt`\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import einops\n",
        "from datasets import load_dataset\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, utils\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.gridspec as gridspec\n",
        "import random\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    \"\"\"\n",
        "    Sets the random seed for Python, NumPy, and PyTorch to ensure reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # The following two lines are crucial for CUDA determinism\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# =====================================================================================\n",
        "# 1. SETUP: Model and Data Loading (Confirmed Working)\n",
        "# =====================================================================================\n",
        "def load_model_and_data(model_name: str, dataset_id: str, dataset_subset: str):\n",
        "    print(\"--- Starting Final Model & Data Loading Process ---\")\n",
        "\n",
        "    print(f\"Step 1/3: Loading original Hugging Face components for '{model_name}'...\")\n",
        "    hf_model = AutoModel.from_pretrained(model_name)\n",
        "    hf_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    hf_config = AutoConfig.from_pretrained(model_name)\n",
        "    print(\" -> Success.\")\n",
        "\n",
        "    print(\"Step 2/3: Manually building and populating HookedTransformer model...\")\n",
        "    model_config = HookedTransformerConfig(\n",
        "        d_model=hf_config.hidden_size,\n",
        "        d_head=hf_config.hidden_size // hf_config.num_attention_heads,\n",
        "        n_layers=hf_config.num_hidden_layers,\n",
        "        n_heads=hf_config.num_attention_heads,\n",
        "        d_vocab=hf_config.vocab_size,\n",
        "        d_mlp=hf_config.intermediate_size,\n",
        "        act_fn=hf_config.hidden_act,\n",
        "        n_ctx=hf_config.max_position_embeddings,\n",
        "        tokenizer_name=model_name,\n",
        "        normalization_type=\"LN\",\n",
        "        model_name=model_name,\n",
        "    )\n",
        "    model = HookedTransformer(model_config)\n",
        "    model.load_state_dict(hf_model.state_dict(), strict=False)\n",
        "    model.eval()\n",
        "    model.tokenizer = hf_tokenizer\n",
        "    print(\" -> Model ready.\")\n",
        "\n",
        "    print(f\"Step 3/3: Loading dataset '{dataset_id}/{dataset_subset}'...\")\n",
        "    dataset = load_dataset(dataset_id, name=dataset_subset, trust_remote_code=True)\n",
        "    validation_dataset = dataset[\"validation\"]\n",
        "    print(\" -> Dataset loading complete.\")\n",
        "\n",
        "    print(\"\\n--- Model and Data Ready for Analysis ---\")\n",
        "    return model, validation_dataset\n",
        "\n",
        "# =====================================================================================\n",
        "# 2. ANALYSIS (DEFINITIVE LOGIC FIX)\n",
        "# =====================================================================================\n",
        "def get_attention_head_outputs(model: HookedTransformer, text: str):\n",
        "    hook_names = [utils.get_act_name(\"z\", i) for i in range(model.cfg.n_layers)]\n",
        "\n",
        "    _, cache = model.run_with_cache(\n",
        "        model.to_tokens(text),\n",
        "        names_filter=lambda name: name in hook_names\n",
        "    )\n",
        "    all_head_outputs = torch.stack([cache[name] for name in hook_names])\n",
        "    return all_head_outputs\n",
        "\n",
        "def analyze_cls_token_contribution(head_outputs: torch.Tensor, model: HookedTransformer):\n",
        "    cls_token_outputs = head_outputs[:, :, 0, :, :]\n",
        "    head_contributions = torch.linalg.norm(cls_token_outputs, dim=-1)\n",
        "    return head_contributions.mean(dim=1)\n",
        "\n",
        "# =====================================================================================\n",
        "# 3. VISUALIZATION\n",
        "# =====================================================================================\n",
        "def plot_heatmap_with_explanation(scores: np.ndarray, max_score_idx: tuple, title: str, filename: str):\n",
        "    \"\"\"Plots a heatmap with labeled axes and a dynamic explanation panel.\"\"\"\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    gs = gridspec.GridSpec(1, 2, width_ratios=[2.5, 1])\n",
        "\n",
        "    ax_heatmap = fig.add_subplot(gs[0, 0])\n",
        "    sns.heatmap(scores, cmap=\"viridis\", ax=ax_heatmap, cbar_kws={'label': 'Contribution Score (L2 Norm)'})\n",
        "\n",
        "    n_layers, n_heads = scores.shape\n",
        "    y_labels = [f\"L{i}\" for i in range(n_layers)]\n",
        "    x_labels = [f\"H{i}\" for i in range(n_heads)]\n",
        "    ax_heatmap.set_yticklabels(y_labels, rotation=0)\n",
        "    ax_heatmap.set_xticklabels(x_labels, rotation=45, ha=\"right\")\n",
        "    ax_heatmap.set_title(\"Attention Head Contributions to [CLS] Token\")\n",
        "    ax_heatmap.set_ylabel(\"Layer\")\n",
        "    ax_heatmap.set_xlabel(\"Head\")\n",
        "\n",
        "    ax_text = fig.add_subplot(gs[0, 1])\n",
        "    ax_text.axis('off')\n",
        "\n",
        "    most_influential_head_str = f\"L{max_score_idx[0]}-H{max_score_idx[1]}\"\n",
        "\n",
        "    text_content = [\n",
        "        (\"How to Read This Heatmap\", 16, 'bold', 0.95),\n",
        "        (\"■ Layer (Y-axis): Model Depth\", 12, 'bold', 0.85),\n",
        "        (\"  • L0-L3 (Early): Process basic syntax.\", 11, 'normal', 0.80),\n",
        "        (\"  • L8-L11 (Deep): Handle abstract semantics.\", 11, 'normal', 0.75),\n",
        "        (\"\\n■ Head (X-axis): Parallel Specialists\", 12, 'bold', 0.68),\n",
        "        (\"  • Each layer has 12 heads focusing on different\", 11, 'normal', 0.63), (\"    word relationships.\", 11, 'normal', 0.59),\n",
        "        (\"\\n■ Color (Heat): Contribution Strength\", 12, 'bold', 0.52),\n",
        "        (\"  • Bright Yellow: Critical for the task.\", 11, 'normal', 0.47), (\"  • Dark Purple: Less important for the task.\", 11, 'normal', 0.42),\n",
        "        (\"\\n■ Key Finding for This Run\", 12, 'bold', 0.35),\n",
        "        (f\"  • The brightest spot is {most_influential_head_str}, showing\", 11, 'normal', 0.30),\n",
        "        (\"    the model has learned specialized 'circuits'\", 11, 'normal', 0.25), (\"    for semantic comparison.\", 11, 'normal', 0.20),\n",
        "    ]\n",
        "\n",
        "    for content, size, weight, y_pos in text_content:\n",
        "        ax_text.text(0.0, y_pos, content, transform=ax_text.transAxes, fontsize=size, fontweight=weight, va='top')\n",
        "\n",
        "    plt.suptitle(title, fontsize=20)\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"\\nHeatmap with explanation saved to {filename}\")\n",
        "\n",
        "def plot_distributions_with_examples(scores: np.ndarray, filename: str):\n",
        "    \"\"\"\n",
        "    Plots distributions and a table of sentence examples in a single figure.\n",
        "    \"\"\"\n",
        "    # MODIFICATION: Further tighten the layout\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "    gs = gridspec.GridSpec(2, 2, height_ratios=[1, 0.4])\n",
        "\n",
        "    # --- Top Left Plot: Histogram ---\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    all_scores_flat = scores.flatten()\n",
        "    sns.histplot(all_scores_flat, kde=False, ax=ax1, bins=30)\n",
        "    ax1.set_title('Distribution of All Head Contributions')\n",
        "    ax1.set_xlabel('Contribution Score (L2 Norm)')\n",
        "    ax1.set_ylabel('Frequency')\n",
        "\n",
        "    # --- Top Right Plot: Bar plot per layer ---\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    layer_means = scores.mean(axis=1)\n",
        "\n",
        "    layer_indices_str = [f\"L{i}\" for i in range(len(layer_means))]\n",
        "    sns.barplot(x=layer_indices_str, y=layer_means, ax=ax2, palette=\"Blues_d\")\n",
        "\n",
        "    ax2.set_title('Average Contribution per Layer')\n",
        "    ax2.set_xlabel('Layer')\n",
        "    ax2.set_ylabel('Average Contribution Score (Log Scale)')\n",
        "    ax2.set_yscale('log')\n",
        "    ax2.grid(True, which='both', axis='y', linestyle='--', linewidth=0.7)\n",
        "\n",
        "    # --- Bottom Plot: Table of Examples ---\n",
        "    ax3 = fig.add_subplot(gs[1, :])\n",
        "    ax3.axis('off')\n",
        "    ax3.set_title(\"\\nCausal Sentence Examples (for illustration)\", fontsize=14, pad=10)\n",
        "\n",
        "    table_data = [\n",
        "        [\"Paraphrase (High Sim, Low Overlap)\", \"A boy is playing the guitar.\", \"A young man is performing on a musical instrument.\"],\n",
        "        [\"Semantic Difference (Low Sim, High Overlap)\", \"The cat is chasing the dog.\", \"The dog is chasing the cat.\"],\n",
        "        [\"Inference (High Sim, Med Overlap)\", \"The government passed a new law.\", \"A bill was approved by congress.\"]\n",
        "    ]\n",
        "    col_labels = [\"Example Type (Why deep layers are needed)\", \"Sentence 1\", \"Sentence 2\"]\n",
        "\n",
        "    table = ax3.table(cellText=table_data, colLabels=col_labels, loc='center', cellLoc='left', colWidths=[0.32, 0.34, 0.34])\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(11)\n",
        "    table.scale(1.1, 1.8)\n",
        "\n",
        "    plt.suptitle('Analysis of Head Contributions & Causal Sentence Examples', fontsize=18)\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"Distribution plots with examples saved to {filename}\")\n",
        "\n",
        "# =====================================================================================\n",
        "# 4. MAIN EXECUTION\n",
        "# =====================================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    set_seed(42)\n",
        "\n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "    sns.set_context(\"paper\", font_scale=1.2)\n",
        "    # Optional: For journals requiring serif fonts (e.g., Times New Roman)\n",
        "    # plt.rcParams['font.family'] = 'serif'\n",
        "    # plt.rcParams['font.serif'] = ['Times']\n",
        "\n",
        "    MODEL_NAME = \"cl-nagoya/ruri-base-v2\"\n",
        "    DATASET_ID = \"shunk031/JGLUE\"\n",
        "    DATASET_SUBSET = \"JSTS\"\n",
        "    NUM_SAMPLES = 1457\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"\\n--- Using device: {device} ---\")\n",
        "\n",
        "    model, dataset = load_model_and_data(MODEL_NAME, DATASET_ID, DATASET_SUBSET)\n",
        "    model.to(device)\n",
        "\n",
        "    fixed_dataset = dataset.shuffle(seed=42)\n",
        "\n",
        "    all_scores_s1 = []\n",
        "    all_scores_s2 = []\n",
        "\n",
        "    print(f\"\\nAnalyzing {len(fixed_dataset)} samples from the dataset on {device}...\")\n",
        "\n",
        "    for sample in tqdm(fixed_dataset):\n",
        "        sentence1, sentence2 = sample['sentence1'], sample['sentence2']\n",
        "\n",
        "        head_outputs_s1 = get_attention_head_outputs(model, sentence1)\n",
        "        scores_s1 = analyze_cls_token_contribution(head_outputs_s1, model)\n",
        "        all_scores_s1.append(scores_s1)\n",
        "\n",
        "        head_outputs_s2 = get_attention_head_outputs(model, sentence2)\n",
        "        scores_s2 = analyze_cls_token_contribution(head_outputs_s2, model)\n",
        "        all_scores_s2.append(scores_s2)\n",
        "\n",
        "    avg_scores_total = (torch.stack(all_scores_s1).mean(dim=0) + torch.stack(all_scores_s2).mean(dim=0)).cpu().numpy() / 2\n",
        "\n",
        "    max_score_idx = np.unravel_index(np.argmax(avg_scores_total), avg_scores_total.shape)\n",
        "\n",
        "    plot_heatmap_with_explanation(avg_scores_total, max_score_idx, \"Average Contribution of Attention Heads to [CLS] Token (JSTS)\", \"attention_head_contribution_heatmap_with_explanation.png\")\n",
        "\n",
        "    plot_distributions_with_examples(avg_scores_total, \"attention_head_distributions_with_examples.png\")\n",
        "\n",
        "    print(\"\\n--- Analysis Complete ---\")\n",
        "\n",
        "    print(f\"Most influential head found at L{max_score_idx[0]}-H{max_score_idx[1]}.\")\n",
        "    print(\"This marks the successful completion of Phase 1's initial exploration.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "5Ywg2Io846UH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminary Experiment"
      ],
      "metadata": {
        "id": "NUMWF6a8-EZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup_and_run.py --mode demo"
      ],
      "metadata": {
        "id": "O-k71C3nZPy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup_and_run.py --mode full"
      ],
      "metadata": {
        "id": "kSYY8VE-ZcCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run_all_experiments.sh"
      ],
      "metadata": {
        "id": "b4VDwSH7aWgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wsQfIiIrA5NW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Rk5S1Tt-88Jb",
        "EBapNpZt9LGL",
        "_b6TnFcN9S6-",
        "xqVX9Sgm9ct2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}